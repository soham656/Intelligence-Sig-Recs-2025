{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f64c30-415b-48a5-9b95-26d3296b7679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SOHAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\SOHAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SOHAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e570f088-a920-4cff-b98b-1e33511edc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all i took a dataset, did the text preprocessing as removing the stopwords, lemmatization to reduce the words to its root words and then used a\n",
    "#pretrained model asword2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b06ad8-4331-45d8-9d17-ef6df73a513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SOHAM'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9382298-f1c6-4f70-aaf3-a8828a784819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will Ã¼ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: msgs, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = pd.read_csv(\"Spam.txt\",sep = \"\\t\", names = [\"label\",\"msgs\"])\n",
    "msgs.msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a019a0-d5b6-4acd-a25d-61e453f66ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1391e4-b356-4a09-b548-dc42ff52289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0541d513-9a78-40f0-a473-667a207f6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(msgs)):\n",
    " \n",
    "    review = re.sub('[^a-zA-Z]', ' ', msgs['msgs'][i]).lower().split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in review if word not in stopwords.words('english')]\n",
    "    corpus.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5565cd2-9c42-4bd9-9e20-44d117b34706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea505d17-a389-4dcb-a236-712294767d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ str(x).split() for x in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7c681-514f-4f06-bf43-a51d2bb39ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff67cbee-c9bd-4be0-a4fa-c75c9f10aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(data,vector_size = 100 , workers = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d10b9e7-60d0-40c2-a02b-183ff8acd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1a0ed60f920>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3529dbb6-159d-46e2-b1f4-f7c7f07b85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(w2v.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81fb8268-4965-4e03-bd35-0f1ded536050",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [w2v.wv[word] for word in words]\n",
    "df = pd.DataFrame({'word': words, 'embedding': vectors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d368091-338f-4eec-9ed7-3dafc917e184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'u',</td>\n",
       "      <td>[-0.5182684, 0.9273665, 0.6103901, 0.24727812,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'call',</td>\n",
       "      <td>[0.048973553, 0.97850394, 0.24646181, -0.44393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u</td>\n",
       "      <td>[1.390851, 0.21068962, -0.98538977, -0.7432007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'ur',</td>\n",
       "      <td>[-0.110089764, 0.9223673, 0.18572308, -0.60065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'get',</td>\n",
       "      <td>[-0.08264734, 0.71237934, -0.018178705, -0.527...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word                                          embedding\n",
       "0     'u',  [-0.5182684, 0.9273665, 0.6103901, 0.24727812,...\n",
       "1  'call',  [0.048973553, 0.97850394, 0.24646181, -0.44393...\n",
       "2        u  [1.390851, 0.21068962, -0.98538977, -0.7432007...\n",
       "3    'ur',  [-0.110089764, 0.9223673, 0.18572308, -0.60065...\n",
       "4   'get',  [-0.08264734, 0.71237934, -0.018178705, -0.527..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad770fe-f312-4f6a-ba57-8d0272da2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('word2vec_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96ce379a-893c-49f3-b690-30cfbf2f9d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SOHAM'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b55258-161e-4c14-9466-9dad7cffd4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
